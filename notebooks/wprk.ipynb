{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevorkian-mano/Motor_Vehicle_Collisions_Project/blob/main/wprk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtPENukSOe2m",
        "outputId": "adbb4765-c15b-42d7-e3e9-d3c8fed5fff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash==2.15.0\n",
            "  Downloading dash-2.15.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting dash-bootstrap-components\n",
            "  Downloading dash_bootstrap_components-2.0.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting Flask<3.1,>=1.0.4 (from dash==2.15.0)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash==2.15.0)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting dash-html-components==2.0.0 (from dash==2.15.0)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash==2.15.0)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash==2.15.0)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from dash==2.15.0) (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from dash==2.15.0) (2.32.4)\n",
            "Collecting retrying (from dash==2.15.0)\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash==2.15.0) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from dash==2.15.0) (75.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from dash==2.15.0) (8.7.0)\n",
            "INFO: pip is looking at multiple versions of dash-bootstrap-components to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dash-bootstrap-components\n",
            "  Downloading dash_bootstrap_components-2.0.3-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading dash_bootstrap_components-2.0.1-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading dash_bootstrap_components-2.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading dash_bootstrap_components-1.7.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<3.1,>=1.0.4->dash==2.15.0) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<3.1,>=1.0.4->dash==2.15.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask<3.1,>=1.0.4->dash==2.15.0) (8.3.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.12/dist-packages (from Flask<3.1,>=1.0.4->dash==2.15.0) (1.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Werkzeug<3.1->dash==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->dash==2.15.0) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->dash==2.15.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->dash==2.15.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->dash==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->dash==2.15.0) (2025.10.5)\n",
            "Downloading dash-2.15.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m823.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading dash_bootstrap_components-1.7.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, pyngrok, Flask, dash, dash-bootstrap-components\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.2\n",
            "    Uninstalling Flask-3.1.2:\n",
            "      Successfully uninstalled Flask-3.1.2\n",
            "Successfully installed Flask-3.0.3 Werkzeug-3.0.6 dash-2.15.0 dash-bootstrap-components-1.7.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 pyngrok-7.5.0 retrying-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dash==2.15.0 dash-bootstrap-components pyngrok plotly pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3XCZPk6UIS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326cd484-5436-488d-f6de-2a8728dfce80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# paste your token:\n",
        "ngrok.set_auth_token(\"35UVQIkvrzthd18TJK5RWg9cpop_63kdb9Dev1GJJixRfUpk1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChVDP2RHXaO5"
      },
      "outputs": [],
      "source": [
        "# app_nyc_crash_dashboard.py\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output, State\n",
        "import dash_bootstrap_components as dbc\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from pyngrok import ngrok # optional - for local tunneling\n",
        "# ------------------------------------------------------------------\n",
        "# Load dataset\n",
        "# ------------------------------------------------------------------\n",
        "df = pd.read_csv(\"merged_cleaned_dataset.csv\", dtype=str) # load as strings to be safe\n",
        "# Normalize and cast useful columns\n",
        "# Keep original columns but create convenient working columns\n",
        "# Some columns have spaces in names; use exact names from your message.\n",
        "# Convert crash datetime to datetime (coerce errors)\n",
        "df[\"CRASH_DATETIME\"] = pd.to_datetime(df[\"CRASH_DATETIME\"], errors=\"coerce\")\n",
        "# YEAR for slider and groupings\n",
        "df[\"YEAR\"] = df[\"CRASH_DATETIME\"].dt.year\n",
        "# Cast numeric injury/killed counts to numeric (safe)\n",
        "num_cols = [\n",
        "     \"NUMBER OF PERSONS INJURED\", \"NUMBER OF PERSONS KILLED\",\n",
        "     \"NUMBER OF PEDESTRIANS INJURED\", \"NUMBER OF PEDESTRIANS KILLED\",\n",
        "     \"NUMBER OF CYCLIST INJURED\", \"NUMBER OF CYCLIST KILLED\",\n",
        "     \"NUMBER OF MOTORIST INJURED\", \"NUMBER OF MOTORIST KILLED\"\n",
        "]\n",
        "for c in num_cols:\n",
        "     if c in df.columns:\n",
        "          df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
        "     else:\n",
        "          df[c] = 0\n",
        "# Helpful aggregated numeric columns\n",
        "df[\"TOTAL_INJURED\"] = df[[\"NUMBER OF PERSONS INJURED\",\n",
        "                         \"NUMBER OF PEDESTRIANS INJURED\",\n",
        "                         \"NUMBER OF CYCLIST INJURED\",\n",
        "                         \"NUMBER OF MOTORIST INJURED\"]].sum(axis=1)\n",
        "df[\"TOTAL_KILLED\"] = df[[\"NUMBER OF PERSONS KILLED\",\n",
        "                         \"NUMBER OF PEDESTRIANS KILLED\",\n",
        "                         \"NUMBER OF CYCLIST KILLED\",\n",
        "                         \"NUMBER OF MOTORIST KILLED\"]].sum(axis=1)\n",
        "# Safe borough column\n",
        "if \"BOROUGH\" not in df.columns:\n",
        "     df[\"BOROUGH\"] = \"Unknown\"\n",
        "df[\"BOROUGH\"] = df[\"BOROUGH\"].fillna(\"Unknown\")\n",
        "# FULL_ADDRESS fallback\n",
        "if \"FULL ADDRESS\" not in df.columns:\n",
        "     df[\"FULL ADDRESS\"] = df.get(\"ON STREET NAME\", \"\").fillna(\"\") + \", \" + df.get(\"BOROUGH\", \"\")\n",
        "# Latitude / Longitude as numeric\n",
        "for coord in (\"LATITUDE\", \"LONGITUDE\"):\n",
        "     if coord in df.columns:\n",
        "          df[coord] = pd.to_numeric(df[coord], errors=\"coerce\")\n",
        "     else:\n",
        "          df[coord] = np.nan\n",
        "# Parse ALL_VEHICLE_TYPES (which may be a string representation of a list) and create a flattened column\n",
        "def parse_vehicle_list(v):\n",
        "     if pd.isna(v):\n",
        "          return []\n",
        "     # If it's already a Python list object (rare in CSV), handle\n",
        "     if isinstance(v, list):\n",
        "          return [str(x).strip() for x in v if str(x).strip()]\n",
        "     s = str(v).strip()\n",
        "     # Try literal_eval if it's like \"['SUV/Station Wagon', 'Sedan']\"\n",
        "     try:\n",
        "          parsed = ast.literal_eval(s)\n",
        "          if isinstance(parsed, (list, tuple)):\n",
        "               return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "     except Exception:\n",
        "          # fallback: comma-separated\n",
        "          parts = [p.strip() for p in s.split(\",\") if p.strip()]\n",
        "          return parts\n",
        "     return []\n",
        "df[\"VEHICLE_TYPES_LIST\"] = df.get(\"ALL_VEHICLE_TYPES\", \"\").apply(parse_vehicle_list)\n",
        "# Expand vehicle types per row into a flat list column for easier counting\n",
        "all_vehicle_types_flat = [vt for sub in df[\"VEHICLE_TYPES_LIST\"] for vt in sub]\n",
        "vehicle_type_counts = pd.Series(all_vehicle_types_flat).value_counts()\n",
        "# Top 10 vehicle types for charts / heatmap combos\n",
        "TOP_VEHICLE_TYPES = vehicle_type_counts.head(10).index.tolist()\n",
        "# Parse contributing factors (all contributing factors column may be a list or string)\n",
        "def parse_factor_list(v):\n",
        "     if pd.isna(v):\n",
        "          return []\n",
        "     if isinstance(v, list):\n",
        "          return [str(x).strip() for x in v if str(x).strip()]\n",
        "     s = str(v).strip()\n",
        "     try:\n",
        "          parsed = ast.literal_eval(s)\n",
        "          if isinstance(parsed, (list, tuple)):\n",
        "               return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "     except Exception:\n",
        "          parts = [p.strip() for p in s.split(\",\") if p.strip()]\n",
        "          return parts\n",
        "     return []\n",
        "# Try to handle both ALL_CONTRIBUTING_FACTORS and ALL_CONTRIBUTING_FACTORS_STR\n",
        "if \"ALL_CONTRIBUTING_FACTORS\" in df.columns:\n",
        "     df[\"FACTORS_LIST\"] = df[\"ALL_CONTRIBUTING_FACTORS\"].apply(parse_factor_list)\n",
        "elif \"ALL_CONTRIBUTING_FACTORS_STR\" in df.columns:\n",
        "     df[\"FACTORS_LIST\"] = df[\"ALL_CONTRIBUTING_FACTORS_STR\"].apply(parse_factor_list)\n",
        "else:\n",
        "     # fallback to specific columns if provided\n",
        "     parts = []\n",
        "     for i in range(1, 4):\n",
        "          c = f\"CONTRIBUTING FACTOR VEHICLE {i}\"\n",
        "          if c in df.columns:\n",
        "               parts.append(df[c].fillna(\"\").astype(str))\n",
        "     if parts:\n",
        "          df[\"FACTORS_LIST\"] = (pd.Series([\";\".join(x) for x in zip(*parts)]) if parts else pd.Series([[]]*len(df))).apply(\n",
        "               lambda s: parse_factor_list(s))\n",
        "     else:\n",
        "          df[\"FACTORS_LIST\"] = [[] for _ in range(len(df))]\n",
        "all_factors_flat = [f for sub in df[\"FACTORS_LIST\"] for f in sub]\n",
        "factor_counts = pd.Series(all_factors_flat).value_counts()\n",
        "TOP_FACTORS = factor_counts.head(10).index.tolist()\n",
        "# PERSON_TYPE (type of persons involved)\n",
        "if \"PERSON_TYPE\" not in df.columns and \"PERSON_TYPE\" in df.columns:\n",
        "     pass\n",
        "# ensure PERSON_TYPE column exists\n",
        "if \"PERSON_TYPE\" not in df.columns:\n",
        "     if \"PERSON_TYPE\" in df.columns:\n",
        "          df[\"PERSON_TYPE\"] = df[\"PERSON_TYPE\"]\n",
        "     else:\n",
        "          df[\"PERSON_TYPE\"] = df.get(\"PERSON_TYPE\", \"Unknown\").fillna(\"Unknown\")\n",
        "# POSITION_IN_VEHICLE_CLEAN is provided in dataset per your list, ensure it's present\n",
        "if \"POSITION_IN_VEHICLE_CLEAN\" not in df.columns:\n",
        "     df[\"POSITION_IN_VEHICLE_CLEAN\"] = df.get(\"POSITION_IN_VEHICLE_CLEAN\", \"\").fillna(\"Unknown\")\n",
        "# Ensure other person-related columns exist (for new plots)\n",
        "for col in [\"PERSON_AGE\", \"PERSON_SEX\", \"BODILY_INJURY\", \"SAFETY_EQUIPMENT\", \"EMOTIONAL_STATUS\", \"UNIQUE_ID\", \"EJECTION\", \"ZIP CODE\", \"PERSON_INJURY\"]:\n",
        "    if col not in df.columns:\n",
        "        # Create a placeholder column if not found (assuming person-level data is in the merged set)\n",
        "        if col == \"UNIQUE_ID\":\n",
        "            df[col] = df.index + 1\n",
        "        elif col == \"PERSON_AGE\":\n",
        "            df[col] = pd.to_numeric(df.get(col, np.nan), errors='coerce').fillna(0).astype(int) # Coerce age to int, fill missing/bad with 0\n",
        "        elif col in [\"EJECTION\", \"ZIP CODE\", \"PERSON_INJURY\"]:\n",
        "             df[col] = df.get(col, \"Unknown\").fillna(\"Unknown\")\n",
        "        else:\n",
        "            df[col] = df.get(col, \"Unknown\").fillna(\"Unknown\")\n",
        "# Small helper to add jitter to lat/lon to separate overlapping points\n",
        "def jitter_coords(series, scale=0.0006):\n",
        "     # scale tuned for city-level jitter\n",
        "     return series + np.random.normal(loc=0, scale=scale, size=series.shape)\n",
        "# ------------------------------------------------------------------\n",
        "# Create Dash app layout\n",
        "# ------------------------------------------------------------------\n",
        "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.FLATLY])\n",
        "server = app.server\n",
        "# Year slider marks\n",
        "min_year = int(df[\"YEAR\"].min()) if not df[\"YEAR\"].isna().all() else 2010\n",
        "max_year = int(df[\"YEAR\"].max()) if not df[\"YEAR\"].isna().all() else pd.Timestamp.now().year\n",
        "year_marks = {y: str(y) for y in range(min_year, max_year + 1)}\n",
        "app.layout = dbc.Container([\n",
        "     html.H2(\"NYC Crash Analysis Dashboard\", className=\"mt-3 mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col([\n",
        "               html.Label(\"Year range\"),\n",
        "               dcc.RangeSlider(\n",
        "                    id=\"year_slider\",\n",
        "                    min=min_year,\n",
        "                    max=max_year,\n",
        "                    value=[min_year, max_year],\n",
        "                    marks=year_marks,\n",
        "                    tooltip={\"placement\": \"bottom\", \"always_visible\": False},\n",
        "                    step=1,\n",
        "                    allowCross=False\n",
        "               ),\n",
        "          ], width=8),\n",
        "          dbc.Col([\n",
        "               html.Label(\"Borough\"),\n",
        "               dcc.Dropdown(\n",
        "                    id=\"borough_filter\",\n",
        "                    options=[{\"label\": b, \"value\": b} for b in sorted(df[\"BOROUGH\"].dropna().unique())],\n",
        "                    multi=True,\n",
        "                    placeholder=\"Select borough(s)\"\n",
        "               )\n",
        "          ], width=4),\n",
        "     ], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "     dbc.Col([\n",
        "          html.Label(\"Vehicle Type\"),\n",
        "          dcc.Dropdown(\n",
        "               id=\"vehicle_filter\",\n",
        "               options=[{\"label\": v, \"value\": v}\n",
        "                        for v in sorted({vt for sub in df[\"VEHICLE_TYPES_LIST\"] for vt in sub})],\n",
        "               multi=True,\n",
        "               placeholder=\"Select vehicle type(s)\"\n",
        "          )\n",
        "     ], width=6),\n",
        "     dbc.Col([\n",
        "          html.Label(\"Contributing Factor\"),\n",
        "          dcc.Dropdown(\n",
        "               id=\"factor_filter\",\n",
        "               options=[{\"label\": f, \"value\": f}\n",
        "                        for f in sorted({f for sub in df[\"FACTORS_LIST\"] for f in sub})],\n",
        "               multi=True,\n",
        "               placeholder=\"Select contributing factor(s)\"\n",
        "          )\n",
        "     ], width=6),\n",
        "], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col([\n",
        "               html.Label(\"Injury Type / Person Injury\"),\n",
        "               dcc.Dropdown(\n",
        "                    id=\"injury_filter\",\n",
        "                    options=[{\"label\": i, \"value\": i} for i in sorted(df[\"PERSON_INJURY\"].dropna().unique())],\n",
        "                    multi=True,\n",
        "                    placeholder=\"Select injury type(s)\"\n",
        "               )\n",
        "          ], width=6),\n",
        "          dbc.Col([\n",
        "               html.Label(\"Search (e.g., 'Brooklyn 2019 pedestrian')\"),\n",
        "               dbc.Input(id=\"search_input\", placeholder=\"Search text\", type=\"text\")\n",
        "          ], width=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Button(\"Generate Report / Update\", id=\"generate_btn\", color=\"primary\"), width=3),\n",
        "          dbc.Col(html.Div(id=\"summary_text\", style={\"paddingTop\": \"8px\"}), width=9)\n",
        "     ], className=\"mb-3\"),\n",
        "     # Charts organized in cards to separate them visually\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Crashes by Borough\"),\n",
        "                                         dcc.Graph(id=\"crashes_by_borough\")])), md=6),\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Injuries by Borough\"),\n",
        "                                         dcc.Graph(id=\"injuries_by_borough\")])), md=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Crashes by Contributing Factor (Top)\"),\n",
        "                                         dcc.Graph(id=\"crashes_by_factor\")])), md=6),\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Injuries by Position in Vehicle\"),\n",
        "                                         dcc.Graph(id=\"injuries_by_position\")])), md=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- NEW PLOT 1 (Stacked Borough Stats) ---\n",
        "     dbc.Row([\n",
        "         dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Injuries & Fatalities by Borough (Stacked)\"),\n",
        "                                       dcc.Graph(id=\"injuries_by_borough_stacked\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- NEW PLOT 2 (Injuries/Killed Over Time) ---\n",
        "     dbc.Row([\n",
        "         dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Total Injuries & Fatalities Over Time\"),\n",
        "                                       dcc.Graph(id=\"injuries_killed_over_time\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- NEW PLOT 3 (Age Distribution with Stats) ---\n",
        "     dbc.Row([\n",
        "         dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Age Distribution with Statistics\"),\n",
        "                                       dcc.Graph(id=\"age_distribution_hist\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- RE-ADDED: Gender Distribution (as requested) ---\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Gender Distribution in Crashes\"),\n",
        "                                         dcc.Graph(id=\"gender_distribution\")])), md=6),\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Injury Severity Distribution\"),\n",
        "                                         dcc.Graph(id=\"injury_severity\")])), md=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- NEW PLOT 4 (ZIP Code Choropleth) ---\n",
        "     dbc.Row([\n",
        "         dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Crashes by ZIP Code\"),\n",
        "                                       dcc.Graph(id=\"zip_code_choropleth\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- ORIGINAL PLOT 4 & 6 ---\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Safety Equipment Usage\"),\n",
        "                                         dcc.Graph(id=\"safety_equipment\")])), md=6),\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Emotional State Distribution in Crashes\"),\n",
        "                                         dcc.Graph(id=\"emotional_state\")])), md=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Crashes per Year (by Borough)\"),\n",
        "                                         dcc.Graph(id=\"crashes_by_year\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Vehicle Type Distribution (Pie)\"),\n",
        "                                         dcc.Graph(id=\"vehicle_pie\")])), md=6),\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Person Types Involved (Pie)\"),\n",
        "                                         dcc.Graph(id=\"person_type_pie\")])), md=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- NEW PLOT 5 (Injuries by Person Type Over Time) ---\n",
        "     dbc.Row([\n",
        "         dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Injuries by Person Type Over Time\"),\n",
        "                                       dcc.Graph(id=\"injuries_by_person_type\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- ORIGINAL PLOT 5 (Expanded Heatmap) ---\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Vehicle Type vs Contributing Factors (Expanded)\"),\n",
        "                                         dcc.Graph(id=\"expanded_veh_factor\")])), md=12),\n",
        "     ], className=\"mb-3\"),\n",
        "     # --- NEW PLOT 6 (Ejection Status Distribution) ---\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Ejection Status Distribution\"),\n",
        "                                        dcc.Graph(id=\"ejection_status\")])), md=6),\n",
        "     ], className=\"mb-3\"),\n",
        "     dbc.Row([\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Crash Density Map (heat)\"),\n",
        "                                         dcc.Graph(id=\"density_map\")])), md=6),\n",
        "          dbc.Col(dbc.Card(dbc.CardBody([html.H5(\"Crash Locations Map (points)\"),\n",
        "                                         dcc.Graph(id=\"map_chart\")])), md=6),\n",
        "     ], className=\"mb-4\"),\n",
        "     # Hidden divs etc if needed\n",
        "], fluid=True)\n",
        "# -------------------------\n",
        "# Helper: parse search query\n",
        "# -------------------------\n",
        "def parse_search_query(q):\n",
        "     q = (q or \"\").lower()\n",
        "     found = {}\n",
        "     # borough detection\n",
        "     for b in df[\"BOROUGH\"].dropna().unique():\n",
        "          if b and b.lower() in q:\n",
        "               found[\"borough\"] = [b]\n",
        "     # year detection\n",
        "     for y in df[\"YEAR\"].dropna().unique():\n",
        "          try:\n",
        "               if str(int(y)) in q:\n",
        "                    found[\"year\"] = [int(y)]\n",
        "          except Exception:\n",
        "               pass\n",
        "     if \"pedestrian\" in q:\n",
        "          # a heuristic: treat pedestrian as injured/killed persons (you can adjust)\n",
        "          found[\"injury\"] = [\"Injured\", \"Killed\"]\n",
        "     return found\n",
        "# -------------------------\n",
        "# Callback: generate figures\n",
        "# -------------------------\n",
        "@app.callback(\n",
        "     [\n",
        "          Output(\"crashes_by_borough\", \"figure\"),\n",
        "          Output(\"injuries_by_borough\", \"figure\"),\n",
        "          Output(\"crashes_by_factor\", \"figure\"),\n",
        "          Output(\"injuries_by_position\", \"figure\"),\n",
        "          Output(\"crashes_by_year\", \"figure\"),\n",
        "          Output(\"vehicle_pie\", \"figure\"),\n",
        "          Output(\"person_type_pie\", \"figure\"),\n",
        "          # Removed: Output(\"veh_factor_heatmap\", \"figure\"),\n",
        "          Output(\"density_map\", \"figure\"),\n",
        "          Output(\"map_chart\", \"figure\"),\n",
        "          # Removed: Output(\"age_distribution\", \"figure\"),\n",
        "          Output(\"gender_distribution\", \"figure\"), # RE-ADDED\n",
        "          Output(\"injury_severity\", \"figure\"),\n",
        "          Output(\"safety_equipment\", \"figure\"),\n",
        "          Output(\"expanded_veh_factor\", \"figure\"),\n",
        "          Output(\"emotional_state\", \"figure\"),\n",
        "          # NEW PLOTS ADDED TO OUTPUT\n",
        "          Output(\"injuries_by_borough_stacked\", \"figure\"),\n",
        "          Output(\"injuries_killed_over_time\", \"figure\"),\n",
        "          Output(\"age_distribution_hist\", \"figure\"),\n",
        "          Output(\"zip_code_choropleth\", \"figure\"),\n",
        "          Output(\"injuries_by_person_type\", \"figure\"),\n",
        "          Output(\"ejection_status\", \"figure\"),\n",
        "          # END OF NEW PLOTS\n",
        "          Output(\"summary_text\", \"children\"),\n",
        "     ],\n",
        "     Input(\"generate_btn\", \"n_clicks\"),\n",
        "     [\n",
        "          State(\"year_slider\", \"value\"),\n",
        "          State(\"borough_filter\", \"value\"),\n",
        "          State(\"vehicle_filter\", \"value\"),\n",
        "          State(\"factor_filter\", \"value\"),\n",
        "          State(\"injury_filter\", \"value\"),\n",
        "          State(\"search_input\", \"value\"),\n",
        "     ]\n",
        ")\n",
        "def update_dashboard(n_clicks, year_range, boroughs, vehicles, factors, injuries, search_text):\n",
        "     dff = df.copy()\n",
        "     # --- Apply search query (intersect with selected filters) ---\n",
        "     if search_text:\n",
        "          parsed = parse_search_query(search_text)\n",
        "          # Borough filter\n",
        "          if \"borough\" in parsed:\n",
        "               boroughs = list(set(boroughs or dff[\"BOROUGH\"].dropna().unique()) & set(parsed[\"borough\"]))\n",
        "          # Year filter\n",
        "          if \"year\" in parsed:\n",
        "               yr = parsed[\"year\"]\n",
        "               if yr:\n",
        "                    year_range = [\n",
        "                         max(year_range[0], int(yr[0])),\n",
        "                         min(year_range[1], int(yr[0]))\n",
        "                    ]\n",
        "          # Injuries filter\n",
        "          if \"injury\" in parsed:\n",
        "               injuries = list(set(injuries or dff[\"PERSON_INJURY\"].dropna().unique()) & set(parsed[\"injury\"]))\n",
        "     # --- Apply year range ---\n",
        "     if year_range and len(year_range) == 2:\n",
        "          y0, y1 = int(year_range[0]), int(year_range[1])\n",
        "          dff = dff[(dff[\"YEAR\"] >= y0) & (dff[\"YEAR\"] <= y1)]\n",
        "     # --- Apply borough filter ---\n",
        "     if boroughs:\n",
        "          dff = dff[dff[\"BOROUGH\"].isin(boroughs)]\n",
        "     # --- Apply injury filter ---\n",
        "     if injuries:\n",
        "          dff = dff[dff[\"PERSON_INJURY\"].fillna(\"\").astype(str).isin([str(i) for i in injuries])]\n",
        "     # --- Apply vehicle filter ---\n",
        "     if vehicles:\n",
        "          mask = dff[\"VEHICLE_TYPES_LIST\"].apply(lambda lst: any(v in (lst if isinstance(lst, list) else []) for v in vehicles))\n",
        "          dff = dff[mask]\n",
        "     # --- Apply contributing factor filter ---\n",
        "     if factors:\n",
        "          mask = dff[\"FACTORS_LIST\"].apply(lambda lst: any(f in (lst if isinstance(lst, list) else []) for f in factors))\n",
        "          dff = dff[mask]\n",
        "     # ---------- Figures ----------\n",
        "     # 1) Crashes by Borough\n",
        "     crashes_by_borough = dff.groupby(\"BOROUGH\").size().reset_index(name=\"Crashes\").sort_values(\"Crashes\", ascending=False)\n",
        "     fig_borough = px.bar(crashes_by_borough, x=\"BOROUGH\", y=\"Crashes\",\n",
        "                          title=\"Crashes by Borough\", labels={\"Crashes\": \"Number of Crashes\", \"BOROUGH\": \"Borough\"},\n",
        "                          text=\"Crashes\")\n",
        "     fig_borough.update_traces(textposition=\"outside\")\n",
        "     fig_borough.update_layout(margin=dict(t=40, b=20))\n",
        "     # 2) Injuries by Borough\n",
        "     injuries_by_borough = dff.groupby(\"BOROUGH\")[\"TOTAL_INJURED\"].sum().reset_index().sort_values(\"TOTAL_INJURED\", ascending=False)\n",
        "     fig_inj_borough = px.bar(injuries_by_borough, x=\"BOROUGH\", y=\"TOTAL_INJURED\",\n",
        "                              title=\"Total Injuries by Borough\",\n",
        "                              labels={\"TOTAL_INJURED\": \"Total Injured\", \"BOROUGH\": \"Borough\"},\n",
        "                              text=\"TOTAL_INJURED\")\n",
        "     fig_inj_borough.update_traces(textposition=\"outside\")\n",
        "     fig_inj_borough.update_layout(margin=dict(t=40, b=20))\n",
        "     # 3) Crashes by Contributing Factor (top 15)\n",
        "     factor_rows = []\n",
        "     for _, row in dff.iterrows():\n",
        "          for f in row[\"FACTORS_LIST\"]:\n",
        "               factor_rows.append((f, row[\"UNIQUE_ID\"] if \"UNIQUE_ID\" in row else 1))\n",
        "     factor_df = pd.DataFrame(factor_rows, columns=[\"Factor\", \"UID\"]) if factor_rows else pd.DataFrame(columns=[\"Factor\", \"UID\"])\n",
        "     factor_counts_df = factor_df[\"Factor\"].value_counts().head(15).reset_index()\n",
        "     factor_counts_df.columns = [\"Factor\", \"Count\"]\n",
        "     fig_factor = px.bar(factor_counts_df, x=\"Count\", y=\"Factor\", orientation=\"h\",\n",
        "                         title=\"Top Contributing Factors (Top 15)\",\n",
        "                         labels={\"Count\": \"Number of Crashes\", \"Factor\": \"Contributing Factor\"})\n",
        "     fig_factor.update_layout(margin=dict(t=40, b=20), yaxis={'categoryorder':'total ascending'})\n",
        "     # 4) Injuries by Position in Vehicle\n",
        "     pos_df = dff.groupby(\"POSITION_IN_VEHICLE_CLEAN\")[\"TOTAL_INJURED\"].sum().reset_index().sort_values(\"TOTAL_INJURED\", ascending=False)\n",
        "     fig_pos = px.bar(pos_df, x=\"POSITION_IN_VEHICLE_CLEAN\", y=\"TOTAL_INJURED\",\n",
        "                      title=\"Injuries by Position in Vehicle\",\n",
        "                      labels={\"TOTAL_INJURED\": \"Total Injured\", \"POSITION_IN_VEHICLE_CLEAN\": \"Position\"})\n",
        "     fig_pos.update_layout(xaxis_tickangle=-45, margin=dict(t=40, b=80))\n",
        "     # 5) Crashes per Year (line) by Borough\n",
        "     year_group = dff.groupby([\"YEAR\", \"BOROUGH\"]).size().reset_index(name=\"Crashes\")\n",
        "     if not year_group.empty:\n",
        "          fig_year = px.line(year_group, x=\"YEAR\", y=\"Crashes\", color=\"BOROUGH\",\n",
        "                             title=\"Crashes per Year (by Borough)\", markers=True)\n",
        "     else:\n",
        "          fig_year = go.Figure()\n",
        "          fig_year.update_layout(title=\"Crashes per Year (no data for selection)\")\n",
        "     # 6) Vehicle Type Distribution (pie)\n",
        "     veh_rows = [vt for sub in dff[\"VEHICLE_TYPES_LIST\"] for vt in sub]\n",
        "     veh_counts = pd.Series(veh_rows).value_counts()\n",
        "     if veh_counts.empty:\n",
        "          fig_veh_pie = go.Figure()\n",
        "          fig_veh_pie.update_layout(title=\"Vehicle Type Distribution (no data)\")\n",
        "     else:\n",
        "          labels = veh_counts.index.tolist()\n",
        "          values = veh_counts.values.tolist()\n",
        "          fig_veh_pie = px.pie(names=labels, values=values, title=\"Vehicle Type Distribution - for filtered vechile types it includes other vechiles that where also involved in the crash\")\n",
        "     # 7) Person type pie\n",
        "     if \"PERSON_TYPE\" in dff.columns:\n",
        "          person_counts = dff[\"PERSON_TYPE\"].fillna(\"Unknown\").value_counts()\n",
        "          fig_person = px.pie(names=person_counts.index, values=person_counts.values, title=\"Person Types Involved\")\n",
        "     else:\n",
        "          fig_person = go.Figure()\n",
        "          fig_person.update_layout(title=\"No PERSON_TYPE column found\")\n",
        "     # 8) Vehicle Type vs Contributing Factor heatmap (REMOVED - now handled by fig_expanded)\n",
        "     # 9) Density map\n",
        "     df_map = dff.dropna(subset=[\"LATITUDE\", \"LONGITUDE\"]).copy()\n",
        "     if not df_map.empty:\n",
        "          fig_density = px.density_mapbox(df_map, lat=\"LATITUDE\", lon=\"LONGITUDE\", radius=8,\n",
        "                                          center={\"lat\": 40.7128, \"lon\": -74.0060},\n",
        "                                          zoom=9, hover_data=[\"FULL ADDRESS\", \"TOTAL_INJURED\", \"TOTAL_KILLED\", \"CRASH_DATETIME\"],\n",
        "                                          mapbox_style=\"open-street-map\",\n",
        "                                          title=\"Crash Density (Heat)\")\n",
        "     else:\n",
        "          fig_density = go.Figure()\n",
        "          fig_density.update_layout(title=\"No location data to show density\")\n",
        "     # 10) Crash locations points map\n",
        "     if not df_map.empty:\n",
        "          df_map[\"_LAT_JIT\"] = jitter_coords(df_map[\"LATITUDE\"].fillna(0).astype(float), scale=0.0005)\n",
        "          df_map[\"_LON_JIT\"] = jitter_coords(df_map[\"LONGITUDE\"].fillna(0).astype(float), scale=0.0005)\n",
        "          fig_map = px.scatter_mapbox(df_map, lat=\"_LAT_JIT\", lon=\"_LON_JIT\", color=\"BOROUGH\",\n",
        "                                       hover_name=\"FULL ADDRESS\",\n",
        "                                       hover_data={\"FULL ADDRESS\": True,\n",
        "                                                   \"TOTAL_INJURED\": True,\n",
        "                                                   \"TOTAL_KILLED\": True,\n",
        "                                                   \"CRASH_DATETIME\": True,\n",
        "                                                   \"_LAT_JIT\": False, \"_LON_JIT\": False},\n",
        "                                       zoom=9, height=600,\n",
        "                                       title=\"Crash Locations (points)\",\n",
        "                                       mapbox_style=\"open-street-map\")\n",
        "          fig_map.update_traces(marker=dict(size=6, opacity=0.6))\n",
        "          fig_map.update_layout(margin=dict(t=40))\n",
        "     else:\n",
        "          fig_map = go.Figure()\n",
        "          fig_map.update_layout(title=\"No location data to display\")\n",
        "\n",
        "     # 11) Gender Distribution (RE-ADDED)\n",
        "     gender_dist = dff.groupby(\"PERSON_SEX\")[\"UNIQUE_ID\"].count().reset_index(name=\"Count\")\n",
        "     fig_gender = px.pie(gender_dist, names=\"PERSON_SEX\", values=\"Count\", title=\"Gender Distribution in Crashes\")\n",
        "     fig_gender.update_layout(margin=dict(t=40, b=20))\n",
        "\n",
        "     # 12) Injury Severity Distribution\n",
        "     injury_dist = dff.groupby(\"BODILY_INJURY\")[\"UNIQUE_ID\"].count().reset_index(name=\"Count\")\n",
        "     fig_injury = px.bar(injury_dist, x=\"BODILY_INJURY\", y=\"Count\", title=\"Injury Severity Distribution\",\n",
        "                          labels={\"BODILY_INJURY\": \"Injury Severity\", \"Count\": \"Number of Records\"})\n",
        "     fig_injury.update_layout(margin=dict(t=40, b=20))\n",
        "\n",
        "     # 13) Safety Equipment Usage\n",
        "     safety_dist = dff.groupby(\"SAFETY_EQUIPMENT\")[\"UNIQUE_ID\"].count().reset_index(name=\"Count\")\n",
        "     fig_safety = px.pie(safety_dist, names=\"SAFETY_EQUIPMENT\", values=\"Count\", title=\"Safety Equipment Usage\",\n",
        "                          labels={\"SAFETY_EQUIPMENT\": \"Safety Equipment\", \"Count\": \"Number of Records\"})\n",
        "     fig_safety.update_layout(margin=dict(t=40, b=20))\n",
        "\n",
        "     # 14) Expanded Vehicle Type vs Contributing Factors\n",
        "     pair_rows_expanded = []\n",
        "     for _, row in dff.iterrows():\n",
        "          vlist = row[\"VEHICLE_TYPES_LIST\"]\n",
        "          flist = row[\"FACTORS_LIST\"]\n",
        "          for v in vlist:\n",
        "               for f in flist:\n",
        "                    pair_rows_expanded.append((v, f))\n",
        "     if pair_rows_expanded:\n",
        "          pair_df_expanded = pd.DataFrame(pair_rows_expanded, columns=[\"Vehicle\", \"Factor\"])\n",
        "          pivot_expanded = pair_df_expanded.groupby([\"Vehicle\", \"Factor\"]).size().reset_index(name=\"Count\")\n",
        "          pivot_table_expanded = pivot_expanded.pivot(index=\"Vehicle\", columns=\"Factor\", values=\"Count\").fillna(0)\n",
        "          fig_expanded = go.Figure(data=go.Heatmap(\n",
        "               z=pivot_table_expanded.values,\n",
        "               x=pivot_table_expanded.columns.tolist(),\n",
        "               y=pivot_table_expanded.index.tolist(),\n",
        "               hovertemplate=\"Vehicle: %{y}<br>Factor: %{x}<br>Count: %{z}<extra></extra>\"\n",
        "          ))\n",
        "          fig_expanded.update_layout(title=\"Vehicle Type vs Contributing Factors (Expanded View)\",\n",
        "                                     xaxis_nticks=12, margin=dict(t=50))\n",
        "     else:\n",
        "          fig_expanded = go.Figure()\n",
        "          fig_expanded.update_layout(title=\"No data for Vehicle×Factor heatmap for the current selection\")\n",
        "\n",
        "     # 15) Emotional State Distribution\n",
        "     emotional_dist = dff.groupby(\"EMOTIONAL_STATUS\")[\"UNIQUE_ID\"].count().reset_index(name=\"Count\")\n",
        "     fig_emotional = px.bar(emotional_dist, x=\"EMOTIONAL_STATUS\", y=\"Count\", title=\"Emotional State Distribution in Crashes\",\n",
        "                             labels={\"EMOTIONAL_STATUS\": \"Emotional State\", \"Count\": \"Number of Records\"})\n",
        "     fig_emotional.update_layout(margin=dict(t=40, b=20))\n",
        "\n",
        "\n",
        "     # 16) Injuries & Fatalities by Borough (Stacked)\n",
        "     borough_stats = dff.groupby(\"BOROUGH\").agg({\n",
        "         \"TOTAL_INJURED\": \"sum\",\n",
        "         \"TOTAL_KILLED\": \"sum\"\n",
        "     }).reset_index()\n",
        "\n",
        "     fig_stacked = px.bar(borough_stats, x=\"BOROUGH\", y=[\"TOTAL_INJURED\", \"TOTAL_KILLED\"],\n",
        "                         title=\"Injuries & Fatalities by Borough\",\n",
        "                         barmode=\"group\",\n",
        "                         labels={\"value\": \"Count\", \"variable\": \"Type\"},\n",
        "                         color_discrete_map={\"TOTAL_INJURED\": \"#FF9999\", \"TOTAL_KILLED\": \"#660000\"})\n",
        "\n",
        "     fig_stacked.update_layout(\n",
        "         margin=dict(t=40, b=20),\n",
        "         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
        "     )\n",
        "\n",
        "     # 17) Total Injuries & Fatalities Over Time\n",
        "     time_series = dff.groupby(\"YEAR\").agg({\n",
        "         \"TOTAL_INJURED\": \"sum\",\n",
        "         \"TOTAL_KILLED\": \"sum\"\n",
        "     }).reset_index()\n",
        "\n",
        "     fig_time = px.line(time_series, x=\"YEAR\", y=[\"TOTAL_INJURED\", \"TOTAL_KILLED\"],\n",
        "                       title=\"Total Injuries & Fatalities Over Time\",\n",
        "                       markers=True,\n",
        "                       hover_name=\"YEAR\")\n",
        "\n",
        "     fig_time.update_layout(\n",
        "         margin=dict(t=40, b=20),\n",
        "         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
        "     )\n",
        "\n",
        "     # 18) Age Distribution with Marginal Box Plot\n",
        "     dff[\"PERSON_AGE\"] = pd.to_numeric(dff[\"PERSON_AGE\"], errors='coerce')\n",
        "     fig_age_hist = px.histogram(dff, x=\"PERSON_AGE\", nbins=30,\n",
        "                           marginal=\"box\",\n",
        "                           title=\"Age Distribution with Statistical Summary\",\n",
        "                           hover_data=[\"PERSON_AGE\"])\n",
        "\n",
        "     fig_age_hist.update_layout(\n",
        "         margin=dict(t=40, b=20),\n",
        "         xaxis_title=\"Age\",\n",
        "         yaxis_title=\"Count\"\n",
        "     )\n",
        "\n",
        "     # 19) ZIP Code Choropleth\n",
        "     zip_stats = dff[dff[\"ZIP CODE\"].str.isdigit()].groupby(\"ZIP CODE\").size().reset_index(name=\"Crash Count\")\n",
        "\n",
        "     fig_zip = px.choropleth(zip_stats,\n",
        "                             locations=\"ZIP CODE\",\n",
        "                             locationmode=\"USA-states\",  # Placeholder for demonstration\n",
        "                             color=\"Crash Count\",\n",
        "                             color_continuous_scale=\"Reds\",\n",
        "                             scope=\"usa\",\n",
        "                             title=\"Crashes by ZIP Code (Demonstration - requires GeoJSON for true accuracy)\")\n",
        "\n",
        "     fig_zip.update_layout(\n",
        "         margin=dict(t=40, b=20),\n",
        "         geo=dict(\n",
        "             showland=True,\n",
        "             landcolor=\"lightgray\",\n",
        "             showcoastlines=True,\n",
        "             coastlinecolor=\"white\"\n",
        "         )\n",
        "     )\n",
        "\n",
        "     # 20) Injuries by Person Type Over Time\n",
        "     person_type_time = dff.groupby([\"YEAR\", \"PERSON_TYPE\"]).agg({\n",
        "         \"TOTAL_INJURED\": \"sum\"\n",
        "     }).reset_index()\n",
        "\n",
        "     fig_person_time = px.bar(person_type_time, x=\"YEAR\", y=\"TOTAL_INJURED\", color=\"PERSON_TYPE\",\n",
        "                             barmode=\"stack\",\n",
        "                             title=\"Injuries by Person Type Over Time\")\n",
        "\n",
        "     fig_person_time.update_layout(\n",
        "         margin=dict(t=40, b=20),\n",
        "         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
        "     )\n",
        "\n",
        "     # 21) Ejection Status Distribution\n",
        "     ejection_dist = dff.groupby(\"EJECTION\")[\"UNIQUE_ID\"].count().reset_index(name=\"Count\")\n",
        "     ejection_dist = ejection_dist.sort_values(\"Count\", ascending=False)\n",
        "\n",
        "     fig_ejection = px.bar(ejection_dist, x=\"EJECTION\", y=\"Count\",\n",
        "                          title=\"Ejection Status Distribution\",\n",
        "                          color_discrete_sequence=[\"#636EFA\"])\n",
        "\n",
        "     fig_ejection.update_layout(\n",
        "         margin=dict(t=40, b=20),\n",
        "         xaxis_title=\"Ejection Status\",\n",
        "         yaxis_title=\"Count\"\n",
        "     )\n",
        "\n",
        "     # --- Summary text generation ---\n",
        "     total_crashes = len(dff)\n",
        "     total_injuries = dff[\"TOTAL_INJURED\"].sum()\n",
        "     total_killed = dff[\"TOTAL_KILLED\"].sum()\n",
        "     summary = f\"**Data Summary:** {total_crashes:,} crashes, {total_injuries:,} total injured, and {total_killed:,} total killed.\"\n",
        "\n",
        "     return (\n",
        "          fig_borough,\n",
        "          fig_inj_borough,\n",
        "          fig_factor,\n",
        "          fig_pos,\n",
        "          fig_year,\n",
        "          fig_veh_pie,\n",
        "          fig_person,\n",
        "          fig_density,\n",
        "          fig_map,\n",
        "          fig_gender, # RE-ADDED\n",
        "          fig_injury,\n",
        "          fig_safety,\n",
        "          fig_expanded,\n",
        "          fig_emotional,\n",
        "          fig_stacked,\n",
        "          fig_time,\n",
        "          fig_age_hist,\n",
        "          fig_zip,\n",
        "          fig_person_time,\n",
        "          fig_ejection,\n",
        "          summary,\n",
        "     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "yH4XsYfpaFwa",
        "outputId": "ff5b6e3b-1be1-4afd-a6fe-a4c416686fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dashboard running on: NgrokTunnel: \"https://tentaculoid-daron-osteologically.ngrok-free.dev\" -> \"http://localhost:8050\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8050)\n",
        "print(\"Dashboard running on:\", public_url)\n",
        "\n",
        "app.run_server(port=8050)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOObQ3yem9HhxDs4ZRtQZho",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}